{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 512, 512, 3)\n",
      "(478,)\n"
     ]
    }
   ],
   "source": [
    "# load data and shuffle it\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\"\"\"\n",
    "img = cv2.imread(r'data\\TrainingData\\0003.jpg')\n",
    "cv2.imshow('0003 test', img)\n",
    "img = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('after downsampling', img)\n",
    "cv2.waitKey()\n",
    "\"\"\"\n",
    "def bin2class(row):\n",
    "    if row[0] == False and row[1] == False: return 0\n",
    "    elif row[0] == False and row[1] == True: return 1\n",
    "    elif row[0] == True and row[1] == False: return 2\n",
    "    elif row[0] == True and row[1] == True: return 3\n",
    "\n",
    "\n",
    "images = [cv2.imread(file) for file in glob.glob(r'data\\TrainingData\\*.jpg')]\n",
    "#rsize = 152\n",
    "#images = [cv2.resize(cv2.imread(file),(rsize,rsize),interpolation=cv2.INTER_AREA) for file in glob.glob(r'data\\TrainingData\\*.jpg')]\n",
    "x = np.array(images, dtype=np.float64)          # x.shape = N, height, width, channel\n",
    "\n",
    "tags = pd.read_excel(r'data\\DataInfo.xlsx', true_values=[\"'High'\", \"'MIBC'\"], false_values=[\"'Low'\",\"'NMIBC'\"])\n",
    "tags = tags.iloc[:, 1:].to_numpy(dtype=int)     # tags.shape = N, grading, staging\n",
    "y = np.apply_along_axis(bin2class, 1, tags)     # y.shape = (N, ) one-hot encoding\n",
    "\n",
    "# shuffle data\n",
    "N = y.shape[0]\n",
    "shuffle_mask = np.random.shuffle(np.arange(N))\n",
    "x[:] = x[shuffle_mask]\n",
    "y[:] = y[shuffle_mask]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n======locally connected layers======\\n    (F, C, H, W)    S next, params\\nL1: (16, 3, 11, 11) 3 40,   9318400\\nL2: (16, 16, 9, 9)  1 32,   21250048\\nL3: (16, 16, 9, 9)  1 24,   11953152\\n======fully connected layers========\\nF1: (24*24*16, 300)\\nF2: (300, 300)\\nF3: (300, 300)\\n======output layer==================\\nF:  (300, 4)\\nsoftmax\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 4\n",
    "\"\"\"\n",
    "======locally connected layers======\n",
    "    (F, C, H, W)    S next, params\n",
    "L1: (16, 3, 11, 11) 3 40,   9318400\n",
    "L2: (16, 16, 9, 9)  1 32,   21250048\n",
    "L3: (16, 16, 9, 9)  1 24,   11953152\n",
    "======fully connected layers========\n",
    "F1: (24*24*16, 300)\n",
    "F2: (300, 300)\n",
    "F3: (300, 300)\n",
    "======output layer==================\n",
    "F:  (300, 4)\n",
    "softmax\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import LocallyConnected2D, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.layers import LeakyReLU, Dense, Dropout, Flatten, Softmax\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def establish_model():\n",
    "    model = Sequential()\n",
    "    # N, 3, 512, 512, preprocess\n",
    "    model.add(Conv2D(32, 3, padding='same', input_shape=(512, 512, 3), kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "    # N, 32, 256, 256\n",
    "    model.add(Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    # N, 3 ,128, 128\n",
    "    model.add(LocallyConnected2D(16, 11, strides=(3, 3), kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.5))\n",
    "    # N, 16, 40, 40\n",
    "    model.add(LocallyConnected2D(16, 9, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.5))\n",
    "    # N, 16, 32, 32\n",
    "    model.add(LocallyConnected2D(16, 9, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.5))\n",
    "    # N, 16, 24, 24\n",
    "    model.add(Flatten())\n",
    "    # N, 16*24*24\n",
    "    model.add(Dense(300, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(300, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Softmax())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Temp\\Anaconda\\envs\\py368\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Temp\\Anaconda\\envs\\py368\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Temp\\Anaconda\\envs\\py368\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# overfitting on small set of data\n",
    "\n",
    "x_pre, y_pre = x[:30], y[:30]\n",
    "y_pre = to_categorical(y_pre, num_classes)\n",
    "\n",
    "model = establish_model()\n",
    "optim = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "hist = model.fit(x_pre, y_pre, batch_size=15, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(hist.history['acc'])\n",
    "#plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(hist.history['loss'])\n",
    "#plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split for cross validation\n",
    "delim = [120, 240, 360]\n",
    "xs = np.split(x, delim)\n",
    "ys = np.split(y, delim)\n",
    "num_classes = 4\n",
    "\n",
    "# validation\n",
    "loss, acc = 0, 0\n",
    "for vali in range(num_classes):\n",
    "    print(\"====== Cross validation step %d ======\"%(vali+1))\n",
    "    x_train = np.vstack([xs[i] for i in range(num_classes) if i != vali])\n",
    "    x_val = xs[vali]\n",
    "    y_train = to_categorical(np.hstack([ys[i] for i in range(num_classes) if i != vali]), num_classes)\n",
    "    y_val = to_categorical(ys[vali], num_classes)\n",
    "    \n",
    "    # establish model\n",
    "    model = establish_model()\n",
    "    \n",
    "    optim = optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=16, epochs=20, shuffle=True)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.plot(hist.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    loss += hist.history['val_acc'][-1]\n",
    "    acc += hist.history['val_loss'][-1]\n",
    "\n",
    "print(\"average loss: %f\"%(loss/num_classes))\n",
    "print(\"average accuracy: %f\"(%acc/num_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py368_for_ml",
   "language": "python",
   "name": "py368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
